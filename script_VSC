cd /user/leuven/363/vsc36367/pacbiocheck
NOTE: BETTER TO WORK ON LOCAL OTHERWISE QUOTA GETS EXCEEDED cd /local_scratch/vsc36367_pacbiocheck

conda activate qiime2-amplicon-2025.4

mkdir -p raw_data_rc raw_data_cat trimmed_reads

# 1) reverse-complement each input
parallel -j 2 'zcat -f {} | seqtk seq -r - | gzip -c > raw_data_rc/{/.}_rc.fastq.gz' ::: ./*.fastq.gz

# 1b) concatenate original + RC per file (decompress -> concat -> recompress once)
for f in ./*.fastq.gz; do
  b=${f%.gz}  # e.g. ./GC172404.fastq
  cat <(zcat -f "$f") <(zcat -f "raw_data_rc/${b}_rc.fastq.gz") | gzip -c > "raw_data_cat/${b}_cat.fastq.gz"
done

# 2) trim primers (YOU must replace FWD_PRIMER and REV_PRIMER with real sequences)
FWD_PRIMER='AGRGTTYGATYMTGGCTCAG'
REV_PRIMER='AAGTCGTAACAAGGTARCY'

parallel -j 2 'cutadapt -g "$FWD_PRIMER" -a "$REV_PRIMER" --discard-untrimmed --no-indels -j 1 -m 1200 -M 1800 -o trimmed_reads/{/.}_trim.fastq.gz {}' ::: raw_data_cat/*_cat.fastq.gz


3. import sequences as a qiime2 artifact
mkdir -p reads_qza

echo "sample-id,absolute-filepath,direction" > trimmed_manifest.csv
for f in trimmed_reads/*_trim.fastq*; do
  sid=$(basename "$f")
  sid=${sid%_trim.fastq*}
  echo "${sid},$(readlink -f "$f"),forward" >> trimmed_manifest.csv
done
#inspect once: 
column -t -s, trimmed_manifest.csv

#import to qiime

qiime tools import \
  --type SampleData[SequencesWithQuality] \
  --input-path trimmed_manifest.csv \
  --output-path reads_qza/trimmed_reads.qza \
  --input-format SingleEndFastqManifestPhred33

  #check
  qiime demux summarize \
  --i-data reads_qza/trimmed_reads.qza \
  --o-visualization reads_qza/trimmed_reads.qzv

  4. DADA2 denoising
mkdir -p dada2_output
#!/bin/bash
#SBATCH --job-name=dada2
#SBATCH --account=lkulak_daphnia_gp
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --time=08:00:00
#SBATCH --output=logs/dada2_%j.out
#SBATCH --error=logs/dada2_%j.err
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=kristina.yefimak@kuleuven.be

set -euo pipefail

cd "$SLURM_SUBMIT_DIR"

# Conda init (batch-proof)
source /data/leuven/363/vsc36367/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2025.4

# Keep temp files in project (HPC-friendly)
mkdir -p logs qiime2_tmp dada2_output
export TMPDIR="$PWD/qiime2_tmp"
export TMP="$PWD/qiime2_tmp"
export TEMP="$PWD/qiime2_tmp"

# Prevent R/BLAS thread oversubscription
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

# DADA2 (one line to avoid line-continuation issues)
qiime dada2 denoise-single --i-demultiplexed-seqs reads_qza/trimmed_reads.qza --p-trunc-len 0 --p-n-threads 8 --p-n-reads-learn 100000 --p-max-ee 2 --o-table dada2_output/table.qza --o-representative-sequences dada2_output/rep-seqs.qza --o-denoising-stats dada2_output/denoising-stats.qza --verbose


OR

qiime dada2 denoise-single \
  --i-demultiplexed-seqs reads_qza/trimmed_reads.qza \
  --p-trunc-len 0 \
  --p-n-threads 8 \
  --p-n-reads-learn 100000 \
  --p-max-ee 2 \
  --o-table dada2_output/table.qza \
  --o-representative-sequences dada2_output/rep-seqs.qza \
  --o-denoising-stats dada2_output/denoising-stats.qza

#check

qiime metadata tabulate \
  --m-input-file dada2_output/denoising-stats.qza \
  --o-visualization dada2_output/denoising-stats.qzv

5. convert artifact to readable format
 mkdir -p dada2_output_exported

# 1) Export denoising stats (creates a .tsv)
qiime tools export --input-path dada2_output/denoising-stats.qza --output-path dada2_output_exported/denoising-stats


# 2) Export feature table (creates feature-table.biom)
qiime tools export --input-path dada2_output/table.qza --output-path dada2_output_exported/table

# 3) Export representative sequences (creates dna-sequences.fasta)
qiime tools export --input-path dada2_output/rep-seqs.qza --output-path dada2_output_exported/rep-seqs


# 4) Convert BIOM -> TSV (human readable)
biom convert -i dada2_output_exported/table/feature-table.biom -o dada2_output_exported/table/feature-table.tsv --to-tsv

#check
ls dada2_output_exported
head dada2_output_exported/denoising-stats/*.tsv
head dada2_output_exported/table/feature-table.tsv
head dada2_output_exported/rep-seqs/dna-sequences.fasta


6. assign taxonomy
DO NOT DO CLASSIFIER= NEED TOOO MUCH RAM FOR THAT
#first need to make a silva classifier: 
1️⃣ Download SILVA 138.2 SSU NR99 (ONE LI
qiime rescript get-silva-data --p-version 138.2 --p-target SSURef_NR99 --p-include-species-labels --o-silva-sequences silva-138-2-seqs.qza --o-silva-taxonomy silva-138-2-tax.qza
2️⃣ Cull low-quality/problematic sequences (ONE LINE)
qiime rescript cull-seqs --i-sequences silva-138-2-seqs.qza --p-num-degenerates 1 --p-homopolymer-length 12 --p-n-jobs 8 --o-clean-sequences silva-138-2-seqs-cull.qza
3️⃣ Filter sequences by taxonomy & length (ONE LINE)
qiime rescript filter-seqs-length-by-taxon --i-sequences silva-138-2-seqs-cull.qza --i-taxonomy silva-138-2-tax.qza --p-labels Archaea Bacteria --p-min-lens 1200 1200 --p-max-lens 2000 2000 --o-filtered-seqs silva-138-2-filtered.qza --o-discarded-seqs silva-138-2-discarded.qza
4️⃣ Dereplicate reference sequences (ONE LINE)
qiime rescript dereplicate --i-sequences silva-138-2-filtered.qza --i-taxa silva-138-2-tax.qza --p-mode uniq --p-rank-handles domain phylum class order family genus species --o-dereplicated-sequences silva-138-2-derep-seqs.qza --o-dereplicated-taxa silva-138-2-derep-tax.qza
5️⃣ Train the Naive Bayes classifier (ONE LINE)
qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads silva-138-2-derep-seqs.qza --i-reference-taxonomy silva-138-2-derep-tax.qza --o-classifier silva-138-2-nb-classifier.qza
6️⃣ Sanity check (ONE LINE)
qiime tools peek silva-138-2-nb-classifier.qza
#untill here wrong

GET THE SILVA FROM/ Download the correct SILVA classifier (sklearn 1.4.2):
wget -O silva-138-99-nb-classifier.qza https://s3-us-west-2.amazonaws.com/qiime2-data/classifiers/sklearn-1.4.2/silva/silva-138-99-nb-classifier.qza
unzip -t silva-138-99-nb-classifier.qza
#Verify it’s a real QIIME 2 artifact
qiime tools peek silva-138-99-nb-classifier.qza
#Classify your ASVs
mkdir -p taxa && qiime feature-classifier classify-sklearn --i-classifier silva-138-99-nb-classifier.qza --i-reads dada2_output/rep-seqs.qza --p-n-jobs 8 --o-classification taxa/classification.qza --verbose
#Export readable taxonomy
qiime tools export --input-path taxa/classification.qza --output-path taxa


#check:
head -n 5 taxa/taxonomy.tsv


7. annotate feature table
1️⃣ Fix taxonomy header for BIOM
sed -i -e '1 s/^Feature ID/#OTUID/' -e '1 s/^Taxon/taxonomy/' taxa/taxonomy.tsv

2️⃣ Add taxonomy metadata to BIOM table
biom add-metadata -i dada2_output_exported/table/feature-table.biom -o dada2_output_exported/table/feature-table_w_tax.biom --observation-metadata-fp taxa/taxonomy.tsv --sc-separated taxonomy

3️⃣ Convert to TSV (human readable)
biom convert -i dada2_output_exported/table/feature-table_w_tax.biom -o dada2_output_exported/table/feature-table_w_tax.tsv --to-tsv --header-key taxonomy

Quick check
head -n 5 dada2_output_exported/table/feature-table_w_tax.tsv


#COMPARE WHICH OF THE 2 SAMPLES HAS MORE DIFFERENT TAXA
-Does one kit recover higher richness / diversity?
-Does one kit recover a broader taxonomic spectrum?
-Are the differences consistent across rarefaction depths?

3️⃣ Step 1 — Generate alpha diversity in QIIME 2
#Pick a depth that both samples support:
qiime feature-table summarize --i-table dada2_output/table.qza --o-visualization dada2_output/table.qzv
#Then run rarefaction with a chosen depth (example uses 20000—replace if needed):
qiime diversity alpha-rarefaction --i-table dada2_output/table.qza --p-max-depth 20000 --p-steps 20 --p-metrics observed_features --p-metrics shannon --o-visualization alpha_rarefaction.qzv

#alpha:
qiime diversity alpha --i-table dada2_output/table.qza --p-metric observed_features --o-alpha-diversity observed_features.qza

#Also compute Shannon (accounts for evenness):
qiime diversity alpha --i-table dada2_output/table.qza --p-metric shannon --o-alpha-diversity shannon.qza

#Export:

mkdir -p exported_alpha && qiime tools export --input-path observed_features.qza --output-path exported_alpha/observed_features
qiime tools export --input-path shannon.qza --output-path exported_alpha/shannon




RAREFACTION CURVES
qiime diversity alpha-rarefaction \
  --i-table dada2_output/table.qza \
  --p-max-depth 20000 \
  --o-visualization alpha_rarefaction.qzv
#Higher curve = higher richness

5️⃣ Step 3 — Export to R for proper comparison
qiime tools export --input-path dada2_output/table.qza --output-path exported
qiime tools export --input-path taxonomy.qza --output-path exported
_______________________________________________________
IN RSTUDIO

library(phyloseq)
library(vegan)

otu <- import_biom("exported/feature-table.biom")
tax <- read.table("exported/taxonomy.tsv", sep="\t", header=TRUE)
tax_mat <- as.matrix(do.call(rbind, strsplit(tax$Taxon, ";")))
rownames(tax_mat) <- tax$Feature.ID
ps <- phyloseq(otu, tax_table(tax_mat))

estimate_richness(ps, measures = c("Observed", "Shannon"))

#This gives you direct richness numbers per extraction kit.
______________________________________________
ps_rel <- transform_sample_counts(ps, function(x) x / sum(x))
dist <- vegdist(t(otu_table(ps_rel)), method = "bray")
dist
#This gives a Bray–Curtis distance between the two kits (0 = identical, 1 = completely different).
